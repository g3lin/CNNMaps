{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_alexnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMtk6qK0t9lCRoMa2iRK8WF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5C26mAqT2-ME","colab_type":"code","outputId":"a3a3f7bf-5178-447e-8441-8fefe5edfd54","executionInfo":{"status":"ok","timestamp":1586004502525,"user_tz":-120,"elapsed":25999,"user":{"displayName":"Julien Brosseau","photoUrl":"https://lh5.googleusercontent.com/-Uack_F0uJ0c/AAAAAAAAAAI/AAAAAAAAAHk/fiTPiqUiz0A/s64/photo.jpg","userId":"00920853515232236248"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jiD64M8G3aej","colab_type":"code","outputId":"df37c89f-4ce2-49ba-886c-df32cc8c45a4","executionInfo":{"status":"ok","timestamp":1586004502538,"user_tz":-120,"elapsed":25993,"user":{"displayName":"Julien Brosseau","photoUrl":"https://lh5.googleusercontent.com/-Uack_F0uJ0c/AAAAAAAAAAI/AAAAAAAAAHk/fiTPiqUiz0A/s64/photo.jpg","userId":"00920853515232236248"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/Projet SatMap/Implementation"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Projet SatMap/Implementation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9w2f_6vVspzH","colab_type":"code","outputId":"f219510c-bc02-4ab3-9db1-f33396636fe9","executionInfo":{"status":"ok","timestamp":1586004511460,"user_tz":-120,"elapsed":34906,"user":{"displayName":"Julien Brosseau","photoUrl":"https://lh5.googleusercontent.com/-Uack_F0uJ0c/AAAAAAAAAAI/AAAAAAAAAHk/fiTPiqUiz0A/s64/photo.jpg","userId":"00920853515232236248"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"source":["!pip install tifffile"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tifffile\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/e8/76979051a2a15b23e2652a3cdeb7d3dfec518c54138bd0f8b5a5ef2c267a/tifffile-2020.2.16-py3-none-any.whl (130kB)\n","\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n","\u001b[?25hCollecting imagecodecs>=2020.1.31\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c0/a2001ce40ddf86f5944a111d61a8bb2799d10e169ba47979bc6c821cf8be/imagecodecs-2020.2.18-cp36-cp36m-manylinux2014_x86_64.whl (18.1MB)\n","\u001b[K     |████████████████████████████████| 18.1MB 196kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.18.2)\n","Installing collected packages: imagecodecs, tifffile\n","Successfully installed imagecodecs-2020.2.18 tifffile-2020.2.16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_6im9feB7HUK","colab_type":"code","outputId":"0ad50dae-a6cc-41d7-fbcc-7969bdc2e0df","executionInfo":{"status":"error","timestamp":1586004925344,"user_tz":-120,"elapsed":4734,"user":{"displayName":"Julien Brosseau","photoUrl":"https://lh5.googleusercontent.com/-Uack_F0uJ0c/AAAAAAAAAAI/AAAAAAAAAHk/fiTPiqUiz0A/s64/photo.jpg","userId":"00920853515232236248"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["# Test du fichier \"treatment.py\" pour la partie \"X_train\" et \"Y_train\"\n","\n","import shapely.affinity\n","import tifffile as tiff\n","import matplotlib.pyplot\n","import csv\n","import sys\n","\n","%matplotlib inline\n","\n","import bin.data_opening as op\n","import bin.treatment as tr\n","\n","csv.field_size_limit(sys.maxsize)\n","\n","# Liste des images annotees\n","LIST_IMG_ID = ('6010_1_2', '6010_4_2', '6010_4_4', '6040_1_0', '6040_1_3', '6040_2_2', \n","         '6040_4_4', '6060_2_3', '6070_2_3', '6090_2_0', '6100_1_3', '6100_2_2',\n","         '6100_2_3', '6110_1_2', '6110_3_1', '6110_4_0', '6120_2_0', '6120_2_2',\n","         '6140_1_2', '6140_3_1', '6150_2_3', '6160_2_1', '6170_0_4', '6170_2_4',\n","         '6170_4_1')\n","# ID des classes respectives : batiments, routes, arbres, rivieres, lacs \n","LIST_POLY_TYPE = ('1', '3', '5', '7', '8')\n","IMG_ID = LIST_IMG_ID[2]\n","POLY_TYPE = LIST_POLY_TYPE[2]\n","\n","LIST_MASK = []\n","LIST_IMG  = []\n","\n","#for IMG_ID in LIST_IMG_ID:\n","\n","# Ouverture des fichiers\n","data_opening = op.DataOpening()\n","\n","x_max, y_min = data_opening.get_size(IMG_ID)\n","polygons = data_opening.get_polygons(IMG_ID, POLY_TYPE)\n","img, img_size = data_opening.get_tiff(IMG_ID)\n","\n","# Traitment des fichiers\n","treatment = tr.Treatment()\n","\n","x_scaler, y_scaler = treatment.get_scalers(img_size, x_max, y_min)\n","\n","list_polygons = shapely.affinity.scale(polygons, xfact=x_scaler, yfact=y_scaler, origin=(0, 0, 0))\n","\n","mask = treatment.get_mask_polygons(img_size, list_polygons)\n","\n","img, mask = treatment.set_size(img, mask)\n","\n","# Sauvegarder les donnees\n","LIST_IMG.append(img)\n","LIST_MASK.append(mask)\n","\n","print(\"taille LIST_MASK :\", len(LIST_MASK))\n","print(\"taille LIST_IMG :\", len(LIST_IMG))\n","\n","#X_train, Y_train = treatment.get_data_train(LIST_IMG, LIST_MASK)\n","\n","#print(\"X_train shape :\", X_train.shape)\n","#print(\"Y_train shape :\", Y_train.shape)\n","\n","from torchvision import transforms, datasets, models\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","\n","import numpy as np\n","\n","from PIL import Image\n","\n","img = Image.open('./data/data_train/buildings/6180_4_4.tif')\n","\n","fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()\n","\n","# Apply the transformations needed\n","import torchvision.transforms as T\n","trf = T.Compose([T.Resize(256),\n","                 T.CenterCrop(224),\n","                 T.ToTensor(), \n","                 T.Normalize(mean = [0.485, 0.456, 0.406], \n","                             std = [0.229, 0.224, 0.225])])\n","inp = trf(img).unsqueeze(0)\n","\n","# Pass the input through the net\n","out = fcn(inp)['out']\n","print (out.shape)\n","\n","om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n","print (om.shape)\n","\n","print (np.unique(om))\n"," \n","preprocess = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","datadir = \"./data/data_train\"\n","train_data = datasets.ImageFolder(datadir, transform=preprocess)\n","\n","img = img.astype(np.float32)\n","\n","print(img.dtype)\n","print(img.shape)\n","\n","img_tensor = preprocess(img)\n","img_tensor.unsqueeze_(0)\n","#mask_tensor = preprocess(mask)\n","\n","img_variable = Variable(img_tensor)\n","\n","#criterion = nn.CrossEntropyLoss()\n","criterion = nn.MSELoss(reduction='sum')\n","\n","optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, momentum=0.9)\n","y = torch.randn(1,1000)\n","#y = Variable(torch.LongTensor(1).random_(5))\n","\n","fc_out = alexnet(img_variable)\n","loss = criterion(fc_out, y)\n","\n","# Zero gradients, perform a backward pass, and update the weights.\n","optimizer.zero_grad()\n","loss.backward()\n","optimizer.step()\n","\n","print(fc_out.data.numpy().argmax())\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["taille LIST_MASK : 1\n","taille LIST_IMG : 1\n","torch.Size([1, 21, 224, 224])\n","(224, 224)\n","[0]\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5503d0ba7e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TiffImageFile' object has no attribute 'astype'"]}]}]}